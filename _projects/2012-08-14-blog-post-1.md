---
title: "Vision Language Model"
collection: projects
permalink: /projects/vlm-research/
date: 2024-08-01 To 2024-12-01
tags:
 - Vision Language Models
 - Deep Learning
 - SigLIP
 - Gemma
 - Computer Vision
 - Natural Language Processing
---
<!-- # Vision Language Model
*August 2024 - December2024* -->
## Project Overview
Building a compact yet powerful Vision Language Model (VLM) by combining state-of-the-art architectures.

[View the project on GitHub](https://github.com/Iaryan-21/PaliGemma-VisionLanguageModel)

## Key Developments
- Architected a sub-3B parameter VLM through innovative integration of 400M SigLIP and 2B Gemma models
- Expanded model capabilities to handle diverse tasks:
 - Remote Sensing Visual Question Answering
 - Complex Question Answering
 - Referring Segmentation

## Technical Details
The project focuses on creating a versatile base VLM that maintains efficiency while handling complex multimodal tasks. By leveraging the visual understanding capabilities of SigLIP and the language processing power of Gemma, we've developed a unified architecture that performs effectively across various computer vision and language understanding challenges.